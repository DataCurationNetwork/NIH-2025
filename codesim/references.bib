
@misc{gebru_datasheets_2021,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
	urldate = {2023-10-06},
	publisher = {arXiv},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumé III, Hal and Crawford, Kate},
	month = dec,
	year = {2021},
	note = {arXiv:1803.09010 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Databases},
	file = {arXiv.org Snapshot:/Users/serickson-local/Zotero/storage/LRKKEBVT/1803.html:text/html;Full Text PDF:/Users/serickson-local/Zotero/storage/HFAXQ2P6/Gebru et al. - 2021 - Datasheets for Datasets.pdf:application/pdf},
}

@article{ullrich_examining_2020,
	title = {Examining {Repositories} for {Simulation} {Data}},
	volume = {30},
	issn = {23059974, 23060271},
	url = {https://www.sne-journal.org/10513},
	doi = {10.11128/sne.30.tn.10513},
	abstract = {Researchers and practicioners often struggle finding or generating adequate data to design, calibrate, or validate simulation models. This leads to greater time and effort allocated to searching for or producing data, rather than performing scientific research itself. This data barrier is especially cumbersome in the long tail of computer science – smaller laboratories typically without access to larger institutions' data sources.},
	language = {en},
	number = {2},
	urldate = {2023-08-29},
	journal = {SNE Simulation Notes Europe},
	author = {Ullrich, Oliver and Potapenko, Victor and Rishe, Naphtali},
	month = jun,
	year = {2020},
	pages = {61--66},
	file = {Ullrich et al. - 2020 - Examining Repositories for Simulation Data.pdf:/Users/serickson-local/Zotero/storage/BHJMIPMM/Ullrich et al. - 2020 - Examining Repositories for Simulation Data.pdf:application/pdf},
}

@article{yang_dependence_2020,
	title = {Dependence of {Atmospheric} {Transport} {Into} the {Arctic} on the {Meridional} {Extent} of the {Hadley} {Cell}},
	volume = {47},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020GL090133},
	doi = {10.1029/2020GL090133},
	abstract = {Recent studies have shown a large spread in the transport of atmospheric tracers into the Arctic among a suite of chemistry climate models and have suggested that this is related to the spread in the meridional extent of the Hadley Cell (HC). Here we examine the HC-transport relationship using an idealized model, where we vary the mean circulation and isolate its impact on transport to the Arctic. It is shown that the poleward transport depends on the relative position between the northern edge of the HC and the tracer source, with maximum transport occurring when the HC edge lies near the middle of the source region. Such dependence highlights the critical role of near-surface transport by the Eulerian mean circulation rather than eddy mixing in the free troposphere and suggests that variations in the HC edge and the tracer source region are both important for modeling Arctic composition.},
	language = {en},
	number = {20},
	urldate = {2023-07-09},
	journal = {Geophysical Research Letters},
	author = {Yang, Huang and Waugh, Darryn W. and Orbe, Clara and Chen, Gang},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020GL090133},
	pages = {e2020GL090133},
	file = {Full Text PDF:/Users/serickson-local/Zotero/storage/QNLH3I5P/Yang et al. - 2020 - Dependence of Atmospheric Transport Into the Arcti.pdf:application/pdf;Snapshot:/Users/serickson-local/Zotero/storage/96QKTCMN/2020GL090133.html:text/html},
}

@misc{noauthor_reference_nodate,
	title = {Reference {Documents}},
	url = {https://www.sisostds.org/ProductsPublications/ReferenceDocuments.aspx},
	urldate = {2023-07-07},
	file = {Reference Documents:/Users/serickson-local/Zotero/storage/YDFVZ88Q/ReferenceDocuments.html:text/html},
}

@misc{noauthor_reference_nodate-1,
	title = {Reference {Documents}},
	url = {https://www.sisostds.org/ProductsPublications/ReferenceDocuments.aspx},
	urldate = {2023-07-07},
	file = {Reference Documents:/Users/serickson-local/Zotero/storage/XJYEPUZC/ReferenceDocuments.html:text/html},
}

@article{ullrich_examining_2020-1,
	title = {Examining {Repositories} for {Simulation} {Data}},
	volume = {30},
	issn = {23059974, 23060271},
	url = {https://www.sne-journal.org/10513},
	doi = {10.11128/sne.30.tn.10513},
	abstract = {Researchers and practicioners often struggle finding or generating adequate data to design, calibrate, or validate simulation models. This leads to greater time and effort allocated to searching for or producing data, rather than performing scientific research itself. This data barrier is especially cumbersome in the long tail of computer science – smaller laboratories typically without access to larger institutions' data sources.},
	language = {en},
	number = {2},
	urldate = {2023-07-06},
	journal = {SNE Simulation Notes Europe},
	author = {Ullrich, Oliver and Potapenko, Victor and Rishe, Naphtali},
	month = jun,
	year = {2020},
	pages = {61--66},
	file = {Ullrich et al. - 2020 - Examining Repositories for Simulation Data.pdf:/Users/serickson-local/Zotero/storage/7IH2IGQI/Ullrich et al. - 2020 - Examining Repositories for Simulation Data.pdf:application/pdf},
}

@techreport{white_house_office_of_science_and_technology_policy_ostp_desirable_2022,
	title = {Desirable {Characteristics} of {Data} {Repositories} for {Federally} {Funded} {Research}},
	url = {https://repository.si.edu/handle/10088/113528},
	abstract = {This document is a work of the United States Government and is in the public domain (see 17 U.S.C. §105). Subject to the stipulations below, it may be distributed and copied with acknowledgment to OSTP. Copyrights to graphics included in this document are reserved by the original copyright holders or their assignees and are used here under the Government’s license and by permission. Requests to use any images must be made to the provider identified in the image credits or to OSTP if no provider is identified. Published in the United States of America, 2021.},
	language = {en},
	urldate = {2023-04-29},
	institution = {Executive Office of the President of the United States},
	author = {{White House Office of Science and Technology Policy (OSTP)}},
	month = may,
	year = {2022},
	doi = {10.5479/10088/113528},
	file = {White House Office of Science and Technology Policy (OSTP) - 2022 - Desirable Characteristics of Data Repositories for.pdf:/Users/serickson-local/Zotero/storage/9HVDFCDB/White House Office of Science and Technology Policy (OSTP) - 2022 - Desirable Characteristics of Data Repositories for.pdf:application/pdf},
}

@article{wickett_critical_2023,
	title = {Critical data modeling and the basic representation model},
	volume = {online},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24745},
	doi = {10.1002/asi.24745},
	abstract = {The increasing role and impact of information systems in modern life calls for new types of information studies that examine sociotechnical factors at play in the development and use of information systems. This article proposes critical data modeling—the use of data modeling and systems analysis techniques to build critical interrogations of information systems—as a method for bridging between social factors and technical systems, presents the Basic Representation Model as an analytical tool for critical data modeling, and discusses the results of critical data modeling of a police arrest record dataset. The Basic Representation Model is a conceptual model of information objects that supports a detailed examination of data modeling and information representation within and across information systems, and functions as a synthesizing concept for existing critical work on information systems. Critical data modeling adds an essential complement to existing approaches to critical information studies by grounding the analysis of an information system in both the technical realities of computational systems and the social realities of our communities.},
	language = {en},
	number = {early release},
	urldate = {2023-02-27},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Wickett, Karen M.},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24745},
	file = {Full Text PDF:/Users/serickson-local/Zotero/storage/9Q97STJL/Wickett - Critical data modeling and the basic representatio.pdf:application/pdf;Snapshot:/Users/serickson-local/Zotero/storage/FBGUR7PE/asi.html:text/html},
}

@misc{noauthor_openpmd_nodate,
	title = {{OpenPMD} standard for simulation data (and metadata) further developed in {PaNOSC} {WP5} {\textbar} {News} {\textbar} {CORDIS} {\textbar} {European} {Commission}},
	url = {https://cordis.europa.eu/article/id/413169-openpmd-standard-for-simulation-data-and-metadata-further-developed-in-panosc-wp5},
	urldate = {2023-02-22},
	file = {OpenPMD standard for simulation data (and metadata) further developed in PaNOSC WP5 | News | CORDIS | European Commission:/Users/serickson-local/Zotero/storage/AQDTFNRY/413169-openpmd-standard-for-simulation-data-and-metadata-further-developed-in-panosc-wp5.html:text/html},
}

@misc{noauthor_physical_nodate,
	title = {Physical {Solar} {Model} ({PSM}) v3 {API} {\textbar} {NREL}: {Developer} {Network}},
	url = {https://developer.nrel.gov/docs/solar/nsrdb/psm3-download/},
	urldate = {2023-02-17},
	file = {Physical Solar Model (PSM) v3 API | NREL\: Developer Network:/Users/serickson-local/Zotero/storage/4C95GH67/psm3-download.html:text/html},
}

@article{sengupta_validation_nodate,
	title = {Validation of the {National} {Solar} {Radiation} {Database} ({NSRDB}) (2005‒2012): {Preprint}},
	abstract = {Publicly accessible, high-quality, long-term, satellite-based solar resource data is foundational and critical to solar technologies to quantify system output predictions and deploy solar energy technologies in grid-tied systems. Solar radiation models have been in development for more than three decades. For many years, the National Renewable Energy Laboratory (NREL) developed and/or updated such models through the National Solar Radiation Data Base (NSRDB). There are two widely used approaches to derive solar resource data from models: (a) an empirical approach that relates ground-based observations to satellite measurements and (b) a physics-based approach that considers the radiation received at the satellite and creates retrievals to estimate clouds and surface radiation. Although empirical methods have been traditionally used for computing surface radiation, the advent of faster computing has made operational physical models viable. The Physical Solar Model (PSM) developed by NREL in collaboration with the University of Wisconsin and the National Oceanic and Atmospheric Administration (NOAA) computes global horizontal irradiance (GHI) using the visible and infrared channel measurements from the Geostationary Operational Environmental Satellites (GOES) system. PSM uses a two-stage scheme that first retrieves cloud properties and then uses those properties to calculate surface radiation. The cloud properties in PSM are generated using the AVHRR Pathfinder Atmospheres-Extended (PATMOS-x) algorithms [5]. Using the cloud mask from PATMOS-x, and aerosol optical depth (AOD) and precipitable water vapor (PWV) from ancillary sources, the direct normal irradiance (DNI) and GHI are computed for clear-sky conditions using the MMAC model. For cloud scenes identified by the cloud mask, the Satellite Algorithm for Surface Radiation Budget (SASRAB) is used to compute the GHI. The DNI for cloud scenes is then computed using the DISC model [6]. The current NSRDB update has a 4-km x 4-km, 30-minute resolution covering 2005 2012. This paper evaluates the PSM-based NSRDB data set using ground-measured data and provides detailed evaluation statistics. The result of the comparison shows a good correlation between the NSRDB and ground data. Further, an outline of the next version of the NSRDB and future plans for enhancement and improvement are provided. This version is expected to be released in September 2015 and will contain data from 1998 2014.},
	language = {en},
	author = {Sengupta, Manajit and Weekley, Andrew and Habte, Aron and Lopez, Anthony},
	file = {Sengupta et al. - Validation of the National Solar Radiation Databas.pdf:/Users/serickson-local/Zotero/storage/36FTMP5C/Sengupta et al. - Validation of the National Solar Radiation Databas.pdf:application/pdf},
}

@article{denholm_supply_2008,
	title = {Supply {Curves} for {Rooftop} {Solar} {PV}-{Generated} {Electricity} for the {United} {States}},
	language = {en},
	journal = {Technical Report},
	author = {Denholm, P and Margolis, R},
	year = {2008},
	file = {Denholm and Margolis - 2008 - Supply Curves for Rooftop Solar PV-Generated Elect.pdf:/Users/serickson-local/Zotero/storage/FGYPQIGQ/Denholm and Margolis - 2008 - Supply Curves for Rooftop Solar PV-Generated Elect.pdf:application/pdf},
}

@article{kambezidis_solar_2017,
	title = {Solar {Radiation} {Modelling}: {The} {Latest} {Version} and {Capabilities} of {MRM}},
	volume = {07},
	issn = {20904541},
	shorttitle = {Solar {Radiation} {Modelling}},
	url = {https://www.omicsonline.com/open-access/solar-radiation-modelling-the-latest-version-and-capabilities-of-mrm-2090-4541-1000e114.php?aid=85816},
	doi = {10.4172/2090-4541.1000e114},
	number = {02},
	urldate = {2023-02-17},
	journal = {Journal of Fundamentals of Renewable Energy and Applications},
	author = {Kambezidis, Harry D},
	year = {2017},
}

@article{sengupta_national_2018,
	title = {The {National} {Solar} {Radiation} {Data} {Base} ({NSRDB})},
	volume = {89},
	issn = {13640321},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S136403211830087X},
	doi = {10.1016/j.rser.2018.03.003},
	language = {en},
	urldate = {2023-02-17},
	journal = {Renewable and Sustainable Energy Reviews},
	author = {Sengupta, Manajit and Xie, Yu and Lopez, Anthony and Habte, Aron and Maclaurin, Galen and Shelby, James},
	month = jun,
	year = {2018},
	pages = {51--60},
	file = {Full Text:/Users/serickson-local/Zotero/storage/WNRMZCLY/Sengupta et al. - 2018 - The National Solar Radiation Data Base (NSRDB).pdf:application/pdf},
}

@misc{noauthor_biomass_nodate,
	title = {Biomass {Scenario} {Model} {\textbar} {Energy} {Analysis} {\textbar} {NREL}},
	url = {https://www.nrel.gov/analysis/bsm/},
	urldate = {2023-02-17},
	file = {Biomass Scenario Model | Energy Analysis | NREL:/Users/serickson-local/Zotero/storage/H37WVGBV/bsm.html:text/html},
}

@misc{noauthor_computer_2022,
	title = {Computer simulation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Computer_simulation&oldid=1129408483},
	abstract = {Computer simulation is the process of mathematical modelling, performed on a computer, which is designed to predict the behaviour of, or the outcome of, a real-world or physical system. The reliability of some mathematical models can be determined by comparing their results to the real-world outcomes they aim to predict. Computer simulations have become a useful tool for the mathematical modeling of many natural systems in physics (computational physics), astrophysics, climatology, chemistry, biology and manufacturing, as well as human systems in economics, psychology, social science, health care and engineering. Simulation of a system is represented as the running of the system's model. It can be used to explore and gain new insights into new technology and to estimate the performance of systems too complex for analytical solutions.Computer simulations are realized by running computer programs that can be either small, running almost instantly on small devices, or large-scale programs that run for hours or days on network-based groups of computers. The scale of events being simulated by computer simulations has far exceeded anything possible (or perhaps even imaginable) using traditional paper-and-pencil mathematical modeling. In 1997, a desert-battle simulation of one force invading another involved the modeling of 66,239 tanks, trucks and other vehicles on simulated terrain around Kuwait, using multiple supercomputers in the DoD High Performance Computer Modernization Program.
Other examples include a 1-billion-atom model of material deformation; a 2.64-million-atom model of the complex protein-producing organelle of all living organisms, the ribosome, in 2005;
a complete simulation of the life cycle of Mycoplasma genitalium in 2012; and the Blue Brain project at EPFL (Switzerland), begun in May 2005 to create the first computer simulation of the entire human brain, right down to the molecular level.Because of the computational cost of simulation, computer experiments are used to perform inference such as uncertainty quantification.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1129408483},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/4THGHRIC/Computer_simulation.html:text/html},
}

@article{mullendore_open_2021,
	title = {Open {Science} {Expectations} for {Simulation}-{Based} {Research}},
	volume = {3},
	issn = {2624-9553},
	url = {https://www.frontiersin.org/articles/10.3389/fclim.2021.763420},
	abstract = {There is strong agreement across the sciences that replicable workflows are needed for computational modeling. Open and replicable workflows not only strengthen public confidence in the sciences, but also result in more efficient community science. However, the massive size and complexity of geoscience simulation outputs, as well as the large cost to produce and preserve these outputs, present problems related to data storage, preservation, duplication, and replication. The simulation workflows themselves present additional challenges related to usability, understandability, documentation, and citation. These challenges make it difficult for researchers to meet the bewildering variety of data management requirements and recommendations across research funders and scientific journals. This paper introduces initial outcomes and emerging themes from the EarthCube Research Coordination Network project titled “What About Model Data? - Best Practices for Preservation and Replicability,” which is working to develop tools to assist researchers in determining what elements of geoscience modeling research should be preserved and shared to meet evolving community open science expectations.Specifically, the paper offers approaches to address the following key questions:• How should preservation of model software and outputs differ for projects that are oriented toward knowledge production vs. projects oriented toward data production?• What components of dynamical geoscience modeling research should be preserved and shared?• What curation support is needed to enable sharing and preservation for geoscience simulation models and their output?• What cultural barriers impede geoscience modelers from making progress on these topics?},
	urldate = {2023-02-09},
	journal = {Frontiers in Climate},
	author = {Mullendore, Gretchen L. and Mayernik, Matthew S. and Schuster, Douglas C.},
	year = {2021},
	file = {Full Text PDF:/Users/serickson-local/Zotero/storage/F2Z4JEAQ/Mullendore et al. - 2021 - Open Science Expectations for Simulation-Based Res.pdf:application/pdf},
}

@article{burt_beyond_nodate,
	title = {Beyond {Explainability}: {A} {Practical} {Guide} to {Managing} {Risk} in {Machine} {Learning} {Models}},
	language = {en},
	author = {Burt, Andrew and Leong, Brenda and Shirrell, Stuart},
	file = {Burt et al. - Beyond Explainability A Practical Guide to Managi.pdf:/Users/serickson-local/Zotero/storage/2QPTRQBZ/Burt et al. - Beyond Explainability A Practical Guide to Managi.pdf:application/pdf},
}

@misc{noauthor_swat_nodate,
	title = {{SWAT} {\textbar} {Soil} \& {Water} {Assessment} {Tool}},
	url = {https://swat.tamu.edu/},
	urldate = {2023-02-03},
	file = {SWAT | Soil & Water Assessment Tool:/Users/serickson-local/Zotero/storage/GGHUTUPQ/swat.tamu.edu.html:text/html},
}

@misc{noauthor_gridded_nodate,
	title = {Gridded {Population} of the {World} ({GPW}), v3 {\textbar} {SEDAC}},
	url = {https://sedac.ciesin.columbia.edu/data/collection/gpw-v3},
	abstract = {The Gridded Population of the World (GPW) collection, now in its fourth version (GPWv4), models the distribution of human population (counts and densities) on a continuous global raster surface. Since the release of the first version of this global population surface in 1995, the essential inputs to GPW have been population census tables and corresponding geographic boundaries. The purpose of GPW is to provide a spatially disaggregated population layer that is compatible with data sets from social, economic, and Earth science disciplines, and remote sensing. It provides globally consistent and spatially explicit data for use in research, policy-making, and communications.},
	urldate = {2023-02-03},
	file = {Gridded Population of the World (GPW), v3 | SEDAC:/Users/serickson-local/Zotero/storage/N4Z2MTNF/gpw-v3.html:text/html},
}

@misc{noauthor_gridded_nodate-1,
	title = {Gridded {Population} of the {World} ({GPW}), v4 {\textbar} {SEDAC}},
	url = {https://sedac.ciesin.columbia.edu/data/collection/gpw-v4},
	abstract = {The Gridded Population of the World (GPW) collection, now in its fourth version (GPWv4), models the distribution of human population (counts and densities) on a continuous global raster surface. Since the release of the first version of this global population surface in 1995, the essential inputs to GPW have been population census tables and corresponding geographic boundaries. The purpose of GPW is to provide a spatially disaggregated population layer that is compatible with data sets from social, economic, and Earth science disciplines, and remote sensing. It provides globally consistent and spatially explicit data for use in research, policy-making, and communications.},
	urldate = {2023-02-03},
	file = {Gridded Population of the World (GPW), v4 | SEDAC:/Users/serickson-local/Zotero/storage/5U4A7V5V/gpw-v4.html:text/html},
}

@misc{noauthor_open_nodate,
	title = {Open {Spatial} {Demographic} {Data} and {Research}},
	url = {https://www.worldpop.org/},
	abstract = {We are a leading geospatial and population research project focused on providing high quality solutions for low-and middle-income countries.},
	language = {en-GB},
	urldate = {2023-02-02},
	journal = {WorldPop},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/BHSDCMR3/www.worldpop.org.html:text/html},
}

@misc{noauthor_ornl_nodate,
	title = {{ORNL} {LandScan} {Viewer} - {Oak} {Ridge} {National} {Laboratory}},
	url = {https://landscan.ornl.gov/},
	abstract = {LandScan Global provides a global population distribution dataset with about a 1-kilometer resolution, representing a 24-hour average population.

LandScan HD provides about a 90-meter resolution population distribution dataset for select areas around the world. It is tailored to the unique geography and data conditions of individual cities, countries or regions. 

LandScan USA is a gridded population dataset with demographic attribution representing daytime and nighttime populations through incorporated census data at the block level at about a 90-meter resolution.  

Both LandScan Global and LandScan HD incorporate current land use and infrastructure data from a variety of sources, apply occupancy estimates from Oak Ridge National Laboratory’s population density tables project, and leverage novel image processing algorithms developed at ORNL to rapidly map structures and neighborhood areas using high-performance computers.},
	urldate = {2023-02-02},
	file = {ORNL LandScan Viewer - Oak Ridge National Laboratory:/Users/serickson-local/Zotero/storage/TB86SFXC/landscan.ornl.gov.html:text/html},
}

@misc{noauthor_paraview_nodate,
	title = {{ParaView}},
	url = {https://www.paraview.org/about/},
	abstract = {ParaView is the world’s leading open source post-processing visualization engine. It integrates with your existing tools and workflows, allowing you to build visualizations to analyze data quickly.},
	language = {en-US},
	urldate = {2023-02-02},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/DVS3DAZM/about.html:text/html},
}

@misc{noauthor_paraview_nodate-1,
	title = {{ParaView} {Companion} {Tools}},
	url = {https://www.paraview.org/companion-tools/},
	language = {en-US},
	urldate = {2023-02-02},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/CE62H2KH/companion-tools.html:text/html},
}

@misc{noauthor_what_nodate,
	title = {What {About} {Model} {Data}? {Best} {Practices} for {Preservation} and {Replicability}},
	url = {https://zoidy.shinyapps.io/ModelDataRubric/#},
	urldate = {2023-01-29},
	file = {What About Model Data? Best Practices for Preservation and Replicability:/Users/serickson-local/Zotero/storage/RUJF9YAM/ModelDataRubric.html:text/html},
}

@misc{noauthor_dcn_nodate,
	title = {{DCN} {CURATED} {Modules} - {Github}},
	url = {https://datacurationnetwork.github.io/CURATED/modules/},
	language = {en},
	urldate = {2023-01-29},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/KZJZCM43/modules.html:text/html},
}

@misc{noauthor_dcn_2023,
	title = {{DCN} data primers - {Github}},
	url = {https://github.com/DataCurationNetwork/data-primers},
	urldate = {2023-01-29},
	month = jan,
	year = {2023},
	note = {original-date: 2018-10-05T13:35:08Z},
}

@article{xu_coupling_2014,
	title = {Coupling the high-complexity land surface model {ACASA} to the mesoscale model {WRF}},
	volume = {7},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/7/2917/2014/},
	doi = {10.5194/gmd-7-2917-2014},
	abstract = {In this study, the Weather Research and Forecasting (WRF) model is coupled with the Advanced Canopy–Atmosphere–Soil Algorithm (ACASA), a high-complexity land surface model. Although WRF is a state-of-the-art regional atmospheric model with high spatial and temporal resolutions, the land surface schemes available in WRF, such as the popular NOAH model, are simple and lack the capability of representing the canopy structure. In contrast, ACASA is a complex multilayer land surface model with interactive canopy physiology and high-order turbulence closure that allows for an accurate representation of heat, momentum, water, and carbon dioxide fluxes between the land surface and the atmosphere. It allows for microenvironmental variables such as surface air temperature, wind speed, humidity, and carbon dioxide concentration to vary vertically within and above the canopy. 

 Surface meteorological conditions, including air temperature, dew point temperature, and relative humidity, simulated by WRF-ACASA and WRF-NOAH are compared and evaluated with observations from over 700 meteorological stations in California. Results show that the increase in complexity in the WRF-ACASA model not only maintains model accuracy but also properly accounts for the dominant biological and physical processes describing ecosystem–atmosphere interactions that are scientifically valuable. The different complexities of physical and physiological processes in the WRF-ACASA and WRF-NOAH models also highlight the impact of different land surface models on atmospheric and surface conditions.},
	language = {English},
	number = {6},
	urldate = {2023-01-29},
	journal = {Geoscientific Model Development},
	author = {Xu, L. and Pyles, R. D. and Paw U, K. T. and Chen, S. H. and Monier, E.},
	month = dec,
	year = {2014},
	note = {Publisher: Copernicus GmbH},
	pages = {2917--2932},
	file = {Full Text PDF:/Users/serickson-local/Zotero/storage/QUZMZ3B4/Xu et al. - 2014 - Coupling the high-complexity land surface model AC.pdf:application/pdf},
}

@article{fejer_data_2020,
	title = {Data from: {Anomalous} {Electron} {Temperature}},
	shorttitle = {Data from},
	url = {https://digitalcommons.usu.edu/all_datasets/128},
	doi = {https://doi.org/10.26078/ZERJ-B751},
	journal = {Browse all Datasets},
	author = {Fejer, Bela},
	month = dec,
	year = {2020},
	file = {"Data from\: Anomalous Electron Temperature" by Bela G. Fejer:/Users/serickson-local/Zotero/storage/AR44TLMM/128.html:text/html},
}

@article{thurgood_aircraft_2021,
	title = {Aircraft {Input} {Files} for {Pylot} and {MachUpX}},
	url = {https://digitalcommons.usu.edu/all_datasets/134},
	doi = {https://doi.org/10.26078/d71p-9a11},
	journal = {Browse all Datasets},
	author = {Thurgood, Jaden},
	month = feb,
	year = {2021},
	file = {"Aircraft Input Files for Pylot and MachUpX" by Jaden Thurgood:/Users/serickson-local/Zotero/storage/SFT37NN5/134.html:text/html},
}

@article{kanda_2d_2021,
	title = {{2D} {Thermo}-{Mechanical} {Simulations} of {Flat} {Subduction} - {Supporting} {Data} for {Research} {Manuscript}},
	url = {https://digitalcommons.usu.edu/all_datasets/181},
	doi = {https://doi.org/10.26078/3BQS-9029},
	journal = {Browse all Datasets},
	author = {Kanda, Ravi and Lowry, Anthony and Buiter, Susanne},
	month = nov,
	year = {2021},
	file = {"2D Thermo-Mechanical Simulations of Flat Subduction - Supporting Data " by Ravi V. S. Kanda, Anthony R. Lowry et al.:/Users/serickson-local/Zotero/storage/FZN27K69/181.html:text/html},
}

@techreport{noauthor_supporting_nodate,
	title = {Supporting {Software} {Preservation} {Services} in {Research} and {Memory} {Organizations} • {CLIR}},
	url = {https://www.clir.org/pubs/reports/supporting-software-preservation-services-in-research-and-memory-organizations/},
	abstract = {Supporting Software Preservation Services in Research and Memory Organizations Co-published by CLIR and the Software Preservation Network Jessica G. Benner, Seth Erickson, Wendy Hagenmaier, Monique Lassere, Christa Williford, Lauren Work November 2022. 60 pp. (electronic only)CLIR pub 182 PDF download {\textgreater}{\textgreater} This white paper from the Software Preservation Network’s Research-in-Practice Working Group presents findings from Read More},
	language = {en-US},
	urldate = {2023-01-29},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/NCI4KIVB/supporting-software-preservation-services-in-research-and-memory-organizations.html:text/html},
}

@misc{noauthor_fair_nodate,
	title = {{FAIR} {Data} {Podcast} {\textbar} {RSpace}},
	url = {https://www.researchspace.com/fair-data-podcast},
	urldate = {2023-01-29},
	file = {FAIR Data Podcast | RSpace:/Users/serickson-local/Zotero/storage/9A8UF8RB/fair-data-podcast.html:text/html},
}

@misc{noauthor_blooms_nodate,
	title = {Blooms {Taxonomy} :: {Resource} for {Educators}},
	url = {https://bloomstaxonomy.net/},
	urldate = {2023-01-29},
	file = {Blooms Taxonomy \:\: Resource for Educators:/Users/serickson-local/Zotero/storage/796GG7F4/bloomstaxonomy.net.html:text/html},
}

@misc{lee_open_2024,
	title = {Open {Source} {Strikes} {Bread} - {New} {Fluffy} {Embeddings} {Model}},
	url = {https://www.mixedbread.ai/blog/mxbai-embed-large-v1},
	author = {Lee, Sean and Shakir, Aamir and Koenig, Darius and Lipp, Julius},
	year = {2024},
}

@misc{noauthor_contribute_nodate,
	title = {Contribute {Data} {\textbar} {FITBIR}},
	url = {https://fitbir.nih.gov/content/contribute-data},
	urldate = {2025-03-07},
	file = {Contribute Data | FITBIR:/Users/serickson-local/Zotero/storage/MNL93AWC/contribute-data.html:text/html},
}

@misc{noauthor_home_nodate,
	title = {Home {\textbar} {FITBIR}},
	url = {https://fitbir.nih.gov/},
	urldate = {2025-03-07},
}

@article{boulesteix_introduction_2020,
	title = {Introduction to statistical simulations in health research},
	volume = {10},
	issn = {2044-6055, 2044-6055},
	url = {https://bmjopen.bmj.com/lookup/doi/10.1136/bmjopen-2020-039921},
	doi = {10.1136/bmjopen-2020-039921},
	abstract = {In health research, statistical methods are frequently used to address a wide variety of research questions. For almost every analytical challenge, different methods are available. But how do we choose between different methods and how do we judge whether the chosen method is appropriate for our specific study? Like in any science, in statistics, experiments can be run to find out which methods should be used under which circumstances. The main objective of this paper is to demonstrate that simulation studies, that is, experiments investigating synthetic data with known properties, are an invaluable tool for addressing these questions. We aim to provide a first introduction to simulation studies for data analysts or, more generally, for researchers involved at different levels in the analyses of health data, who (1) may rely on simulation studies published in statistical literature to choose their statistical methods and who, thus, need to understand the criteria of assessing the validity and relevance of simulation results and their interpretation; and/or (2) need to understand the basic principles of designing statistical simulations in order to efficiently collaborate with more experienced colleagues or start learning to conduct their own simulations. We illustrate the implementation of a simulation study and the interpretation of its results through a simple example inspired by recent literature, which is completely reproducible using the R-script available from online supplemental file 1.},
	language = {en},
	number = {12},
	urldate = {2025-02-27},
	journal = {BMJ Open},
	author = {Boulesteix, Anne-Laure and Groenwold, Rolf Hh and Abrahamowicz, Michal and Binder, Harald and Briel, Matthias and Hornung, Roman and Morris, Tim P and Rahnenführer, Jörg and Sauerbrei, Willi},
	month = dec,
	year = {2020},
	pages = {e039921},
	file = {PDF:/Users/serickson-local/Zotero/storage/EYBWT593/Boulesteix et al. - 2020 - Introduction to statistical simulations in health research.pdf:application/pdf},
}

@misc{noauthor_software_nodate,
	title = {Software {Tools} – {OHDSI}},
	url = {https://www.ohdsi.org/software-tools/},
	language = {en-US},
	urldate = {2025-02-27},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/FKZK6JX7/software-tools.html:text/html},
}

@misc{noauthor_augmentamainpy_nodate,
	title = {{AugmentA}/main.py at main · {KIT}-{IBT}/{AugmentA}},
	url = {https://github.com/KIT-IBT/AugmentA/blob/main/main.py},
	abstract = {AugmentA: Patient-specific Augmented Atrial model Generation Tool - KIT-IBT/AugmentA},
	language = {en},
	urldate = {2025-02-27},
	journal = {GitHub},
	file = {Snapshot:/Users/serickson-local/Zotero/storage/AG3GUXI4/main.html:text/html},
}

@article{kozlowski_readme_2025,
	title = {Readme {Template} for {Data}},
	copyright = {Creative Commons Zero v1.0 Universal},
	url = {https://hdl.handle.net/1813/116815},
	doi = {10.7298/MHNS-ZM71},
	language = {en},
	urldate = {2025-05-11},
	author = {Kozlowski, Wendy Anne},
	year = {2025},
	note = {Medium: text/plain,text/markdown
Publisher: Cornell University Library},
}

@article{bhandari_neupane_characterization_2019,
	title = {Characterization of {Leptazolines} {A}–{D}, {Polar} {Oxazolines} from the {Cyanobacterium} \textit{{Leptolyngbya}} sp., {Reveals} a {Glitch} with the “{Willoughby}–{Hoye}” {Scripts} for {Calculating} {NMR} {Chemical} {Shifts}},
	volume = {21},
	copyright = {https://doi.org/10.15223/policy-029},
	issn = {1523-7060, 1523-7052},
	url = {https://pubs.acs.org/doi/10.1021/acs.orglett.9b03216},
	doi = {10.1021/acs.orglett.9b03216},
	language = {en},
	number = {20},
	urldate = {2025-05-11},
	journal = {Organic Letters},
	author = {Bhandari Neupane, Jayanti and Neupane, Ram P. and Luo, Yuheng and Yoshida, Wesley Y. and Sun, Rui and Williams, Philip G.},
	month = oct,
	year = {2019},
	pages = {8449--8453},
}

@techreport{gruenpeter_defining_2021,
	title = {Defining {Research} {Software}: a controversial discussion},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {Defining {Research} {Software}},
	url = {https://zenodo.org/record/5504016},
	abstract = {Software is essential in modern research; it plays vital roles at multiple stages of the research lifecycle. The term Research Software is widely used in the academic community but, what do we mean when we use these terms? Software and research? When you think of software, you may think of a digital object that is executed on a machine. Yet software is more than just this, it is a complex and evolving artifact. It may be a concept or a project designed to solve a puzzle by a team or a community that develops its functionalities and algorithms, which might not be digital objects. Furthermore, the software artifacts are digital objects, e.g., executables and source code files for different environments. These digital artifacts, which are used in a scholarly setting, might be important in the research process, but should all these be considered Research Software? This report is the result of a discussion examining the scope of the community definition of the FAIR principles for Research Software as part of the work in the FAIR for Research Software working group (FAIR4RS). We aim to clarify the scope of the FAIR principles by identifying which software artifacts the FAIR principles should apply to. This discussion portrayed a complex landscape of software uses in research and existing definitions that can help to better understand the complexity of different types of software in academia. Finally we determine the scope of the FAIR4RS with a short and concise definition of Research Software as a separate metaphor of software in research.},
	urldate = {2025-05-11},
	institution = {Zenodo},
	author = {Gruenpeter, Morane and Katz, Daniel S. and Lamprecht, Anna-Lena and Honeyman, Tom and Garijo, Daniel and Struck, Alexander and Niehues, Anna and Martinez, Paula Andrea and Castro, Leyla Jael and Rabemanantsoa, Tovo and Chue Hong, Neil P. and Martinez-Ortiz, Carlos and Sesink, Laurents and Liffers, Matthias and Fouilloux, Anne Claire and Erdmann, Chris and Peroni, Silvio and Martinez Lavanchy, Paula and Todorov, Ilian and Sinha, Manodeep},
	month = sep,
	year = {2021},
	doi = {10.5281/ZENODO.5504016},
	note = {Version Number: 1},
	keywords = {academic software, definition, FAIR principles, research software, scientific software, software source code},
}

@article{hinsen_dealing_2019,
	title = {Dealing {With} {Software} {Collapse}},
	volume = {21},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1521-9615, 1558-366X},
	url = {https://ieeexplore.ieee.org/document/8701540/},
	doi = {10.1109/MCSE.2019.2900945},
	number = {3},
	urldate = {2025-05-11},
	journal = {Computing in Science \& Engineering},
	author = {Hinsen, Konrad},
	month = may,
	year = {2019},
	pages = {104--108},
	file = {Submitted Version:/Users/serickson-local/Zotero/storage/7I4TDTQY/Hinsen - 2019 - Dealing With Software Collapse.pdf:application/pdf},
}

@unpublished{cosmo_code_2025,
	title = {{CODE} beyond {FAIR}},
	url = {https://inria.hal.science/hal-04930405/document},
	author = {Cosmo, Roberto Di and Granger, Sabrina and Hinsen, Konrad and Jullien, Nicolas and Berre, Daniel Le},
	year = {2025},
	file = {CODE_beyond_FAIR.pdf:/Users/serickson-local/Zotero/storage/3VMQ5S5N/CODE_beyond_FAIR.pdf:application/pdf},
}

@article{dietrich_readme_2025,
	title = {Readme {Template} for {Software}},
	copyright = {Creative Commons Zero v1.0 Universal},
	url = {https://hdl.handle.net/1813/116816},
	doi = {10.7298/H85A-QZ91},
	abstract = {A readme file provides information about a dataset, file(s), or software and is intended to help ensure that the files can be correctly interpreted, by yourself at a later date or by others when sharing or publishing data, code, or software.

These README templates are provided in multiple formats for your to adapt and use for your data:

-.md (markdown, a language for text formatting that can be opened using a markdown editor or as plain text)

-.txt (plain text, which can be opened and edited in a text editor; to download you may need to control-click or right-click and save the file)

The accompanying guide to writing “readme” style metadata for your code and software can be found here: https://data.research.cornell.edu/data-management/sharing/writing-readmes-for-research-code-software/

Information about markdown can be found here: https://www.markdownguide.org/},
	language = {en},
	urldate = {2025-05-11},
	author = {Dietrich, Dianne},
	year = {2025},
	note = {Medium: text/plain,text/markdown
Publisher: Cornell University Library},
}
